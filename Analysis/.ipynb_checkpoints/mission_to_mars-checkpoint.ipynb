{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mission To Mars - Web Scraping Analysis\n",
    "\n",
    "### This Jupyter Notebook file will utilize Splinter and Beautiful Soup to scrape the NASA website and pull the latest news and information related to Mars missions.\n",
    "\n",
    "#### The notebook will accomplish the following:\n",
    "* 1) Scrape the NASA Mars News Site and collect the latest News Title and Paragraph Text and assign to variables.\n",
    "* 2) Visit the url for JPL Featured Space Image and then use splinter to navigate the site and find the image url for the current Featured Mars Image and assign the url string to a variable called featured_image_url.\n",
    "* 3) Visit the Mars Weather twitter account and scrape the latest Mars weather tweet from the page and then save the tweet text for the weather report as a variable called mars_weather.\n",
    "* 4) Visit the Mars Facts webpage here and use Pandas to scrape the table containing facts about the planet including Diameter, Mass, etc. Then, use Pandas to convert the data to a HTML table string.\n",
    "* 5) Visit the USGS Astrogeology site to obtain high resolution images for each of Mar's hemispheres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workbook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary dependencies\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the path to the Google Chrome driver and store it in a variable\n",
    "chrome_driver_path = !which chromedriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the executable path and initialize the chrome browser in splinter\n",
    "executable_path = {'executable_path': chrome_driver_path[0]}\n",
    "chrome_browser = Browser('chrome', **executable_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) NASA Website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign URL variables to visit the NASA website\n",
    "nasa_url = 'https://mars.nasa.gov/news/'\n",
    "# have Chrome navigate to that URL\n",
    "chrome_browser.visit(nasa_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the browser html from the NASA website from the link above to a Beautiful Soup object\n",
    "nasa_html = chrome_browser.html\n",
    "nasa_beautiful_soup = BeautifulSoup(nasa_html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Mars InSight Landing Site Is Just Plain Perfect'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# after running through the total beautiful soup object by doing \"print(nasa_beautiful_soup)\"\n",
    "# and searching for the first article title I saw upon visual inspection of the page\n",
    "# (\"The Mars InSight...\"), I determined the news titles were in a div with class \n",
    "# \"content_title\"\n",
    "\n",
    "# Thus, use the parent element to find the first a tag and save it as `news_title` since\n",
    "# the first tag is the latest by date\n",
    "news_title = nasa_beautiful_soup.find(\"div\", class_='content_title').get_text()\n",
    "news_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'If the InSight landing zone were ice cream, it would be vanilla.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The first paragraph text can be found with similar logic\n",
    "news_paragraph = nasa_beautiful_soup.find('div', class_=\"article_teaser_body\").get_text()\n",
    "news_paragraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) JPL Space Images Featured Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visit the provided URL in Chrome to scrape for the images\n",
    "JPL_url = 'https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars'\n",
    "chrome_browser.visit(JPL_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After inspecting the page using it was determined that the full image button has\n",
    "# id = \"full_image\", thus we use Splinter to find that id\n",
    "JPL_full_image_elem = chrome_browser.find_by_id('full_image')\n",
    "\n",
    "# instruct Chrome to click the full image button\n",
    "JPL_full_image_elem.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After inspecting the subsequent page, it is determine\n",
    "# that the \"More Info\" button needs to be pressed to get access to the \n",
    "# full image. After inspection, the <a> element class is \"button\". Since that is generic,\n",
    "# use the text within the button to click it.\n",
    "JPL_more_info_elem = chrome_browser.find_link_by_partial_text('more info')\n",
    "JPL_more_info_elem.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we are on the page with the full image we need to parse html with BeautifulSoup\n",
    "# to get the image link and store it to a variable\n",
    "JPL_html = chrome_browser.html\n",
    "JPL_img_soup = BeautifulSoup(JPL_html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/spaceimages/images/largesize/PIA18328_hires.jpg'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the relative image url. After page inspection it is determined the image is within an\n",
    "# <img> element with class \"main_image\" nested within a figure with class \"lede\"\n",
    "JPL_img_url_rel = JPL_img_soup.select_one('figure.lede a img').get(\"src\")\n",
    "JPL_img_url_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.jpl.nasa.gov/spaceimages/images/largesize/PIA18328_hires.jpg'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the base url to create an absolute url\n",
    "JPL_base_URL = \"https://www.jpl.nasa.gov\"\n",
    "JPL_absolute_img_url = JPL_base_URL + JPL_img_url_rel\n",
    "JPL_absolute_img_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Mars Weather via Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# have the Chrome browser navigate to the provided Twitter URL\n",
    "mars_twitter_url = 'https://twitter.com/marswxreport?lang=en'\n",
    "chrome_browser.visit(mars_twitter_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the resultant HTML with Beautiful Soup\n",
    "mars_twitter_html = chrome_browser.html\n",
    "mars_weather_soup = BeautifulSoup(mars_twitter_html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, find a tweet with the data-name `Mars Weather`\n",
    "mars_weather_tweet = mars_weather_soup.find('div', attrs={\"class\": \"tweet\", \"data-name\": \"Mars Weather\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sol 2219 (2018-11-03), high -7C/19F, low -71C/-95F, pressure at 8.68 hPa, daylight 06:15-18:33'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Next, search within the tweet for the p tag containing the tweet text\n",
    "found_mars_weather = mars_weather_tweet.find('p', 'tweet-text').get_text()\n",
    "found_mars_weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Mars Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>description</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Equatorial Diameter:</th>\n",
       "      <td>6,792 km</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Polar Diameter:</th>\n",
       "      <td>6,752 km</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mass:</th>\n",
       "      <td>6.42 x 10^23 kg (10.7% Earth)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Moons:</th>\n",
       "      <td>2 (Phobos &amp; Deimos)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Orbit Distance:</th>\n",
       "      <td>227,943,824 km (1.52 AU)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Orbit Period:</th>\n",
       "      <td>687 days (1.9 years)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Surface Temperature:</th>\n",
       "      <td>-153 to 20 °C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>First Record:</th>\n",
       "      <td>2nd millennium BC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recorded By:</th>\n",
       "      <td>Egyptian astronomers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              value\n",
       "description                                        \n",
       "Equatorial Diameter:                       6,792 km\n",
       "Polar Diameter:                            6,752 km\n",
       "Mass:                 6.42 x 10^23 kg (10.7% Earth)\n",
       "Moons:                          2 (Phobos & Deimos)\n",
       "Orbit Distance:            227,943,824 km (1.52 AU)\n",
       "Orbit Period:                  687 days (1.9 years)\n",
       "Surface Temperature:                  -153 to 20 °C\n",
       "First Record:                     2nd millennium BC\n",
       "Recorded By:                   Egyptian astronomers"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dataframe using the link provided from the Mars Facts webpage\n",
    "mars_facts_df = pd.read_html('http://space-facts.com/mars/')[0]\n",
    "# set the columns to more descriptive headers\n",
    "mars_facts_df.columns=['description', 'value']\n",
    "# change the index to \"description\"\n",
    "mars_facts_df.set_index('description', inplace=True)\n",
    "mars_facts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<table border=\"1\" class=\"dataframe\">\\n  <thead>\\n    <tr style=\"text-align: right;\">\\n      <th></th>\\n      <th>value</th>\\n    </tr>\\n    <tr>\\n      <th>description</th>\\n      <th></th>\\n    </tr>\\n  </thead>\\n  <tbody>\\n    <tr>\\n      <th>Equatorial Diameter:</th>\\n      <td>6,792 km</td>\\n    </tr>\\n    <tr>\\n      <th>Polar Diameter:</th>\\n      <td>6,752 km</td>\\n    </tr>\\n    <tr>\\n      <th>Mass:</th>\\n      <td>6.42 x 10^23 kg (10.7% Earth)</td>\\n    </tr>\\n    <tr>\\n      <th>Moons:</th>\\n      <td>2 (Phobos &amp; Deimos)</td>\\n    </tr>\\n    <tr>\\n      <th>Orbit Distance:</th>\\n      <td>227,943,824 km (1.52 AU)</td>\\n    </tr>\\n    <tr>\\n      <th>Orbit Period:</th>\\n      <td>687 days (1.9 years)</td>\\n    </tr>\\n    <tr>\\n      <th>Surface Temperature:</th>\\n      <td>-153 to 20 °C</td>\\n    </tr>\\n    <tr>\\n      <th>First Record:</th>\\n      <td>2nd millennium BC</td>\\n    </tr>\\n    <tr>\\n      <th>Recorded By:</th>\\n      <td>Egyptian astronomers</td>\\n    </tr>\\n  </tbody>\\n</table>'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the pandas dataframe to an HTML table\n",
    "mars_facts_df.to_html()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) USGS Astrogeology Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# navigate to the USGS site with the link provided in the Chrome browser\n",
    "USGS_url = 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'\n",
    "chrome_browser.visit(USGS_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate an empty list to hold all of the scraped image urls\n",
    "hemisphere_image_urls = []\n",
    "\n",
    "# Then, get a list of all of the hemispheres\n",
    "hemisphere_links = chrome_browser.find_by_css(\"a.product-item h3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, loop through those links, click the link, find the sample anchor, and return the href\n",
    "for i in range(len(hemisphere_links)):\n",
    "    # create an empty dictionary\n",
    "    current_hemisphere = {}\n",
    "    \n",
    "    # We have to find the elements on each loop to avoid a stale element exception\n",
    "    chrome_browser.find_by_css(\"a.product-item h3\")[i].click()\n",
    "    \n",
    "    # Next, we find the Sample image anchor tag and extract the href\n",
    "    sample_elem = chrome_browser.find_link_by_text('Sample').first\n",
    "    # set the href into the dictionary\n",
    "    current_hemisphere['img_url'] = sample_elem['href']\n",
    "    \n",
    "    # Get the Hemisphere title and place it in the dictionary\n",
    "    current_hemisphere['title'] = chrome_browser.find_by_css(\"h2.title\").text\n",
    "    \n",
    "    # Append hemisphere dictionary to the list\n",
    "    hemisphere_image_urls.append(current_hemisphere)\n",
    "    \n",
    "    # Finally, we navigate backwards in the browser so that on the next iteration the images\n",
    "    # can be clicked into\n",
    "    chrome_browser.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/cerberus_enhanced.tif/full.jpg',\n",
       "  'title': 'Cerberus Hemisphere Enhanced'},\n",
       " {'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/schiaparelli_enhanced.tif/full.jpg',\n",
       "  'title': 'Schiaparelli Hemisphere Enhanced'},\n",
       " {'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/syrtis_major_enhanced.tif/full.jpg',\n",
       "  'title': 'Syrtis Major Hemisphere Enhanced'},\n",
       " {'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/valles_marineris_enhanced.tif/full.jpg',\n",
       "  'title': 'Valles Marineris Hemisphere Enhanced'}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display all of the found urls\n",
    "hemisphere_image_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally quit out of the Chrome browser\n",
    "chrome_browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
